{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding,default_data_collator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element_datasets(args):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        result[\"A\"] = tokenizer(examples[\"A\"],truncation = True,max_length = 256)\n",
    "        result[\"B\"] = tokenizer(examples[\"B\"],truncation = True,max_length = 256)\n",
    "        result[\"C\"] = tokenizer(examples[\"C\"],truncation = True,max_length = 256)\n",
    "        if tokenizer.is_fast:\n",
    "            result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "        return result\n",
    "\n",
    "    dataset = load_dataset(\"json\", data_files=\"/home/huijie/legal/mymodel/data/SCM.json\")\n",
    "    dataset = dataset.shuffle(seed=42)[\"train\"].rename_column(\"labels\",\"classification\").train_test_split(0.1)\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function, batched=True, remove_columns=[\"class\",\"sentence\"],num_proc =16\n",
    "    )\n",
    "    data_collator = DataCollatorWithPadding(tokenizer,padding= \"max_length\",max_length = 256,pad_to_multiple_of= 8)\n",
    "    return tokenized_datasets[\"train\"],tokenized_datasets[\"test\"],data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A stat\n",
      "count    27506.000000\n",
      "mean       677.076965\n",
      "std         47.875176\n",
      "min        586.000000\n",
      "25%        646.000000\n",
      "50%        675.000000\n",
      "75%        703.000000\n",
      "max       1063.000000\n",
      "dtype: float64\n",
      "B stat\n",
      "count    27506.000000\n",
      "mean       676.187450\n",
      "std         45.858378\n",
      "min        586.000000\n",
      "25%        646.000000\n",
      "50%        675.000000\n",
      "75%        701.000000\n",
      "max       1063.000000\n",
      "dtype: float64\n",
      "C stat\n",
      "count    27506.000000\n",
      "mean       426.275576\n",
      "std        328.079648\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%        641.000000\n",
      "75%        682.000000\n",
      "max       1063.000000\n",
      "dtype: float64\n",
      "label stat\n",
      "count    27506.000000\n",
      "mean       251.143641\n",
      "std        327.567979\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%        654.000000\n",
      "max       1063.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json (r'/home/huijie/legal/mymodel/data/SCM.json',lines=True)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "stat_a = [len(inp) for inp in df[\"A\"]]\n",
    "stat_b = [len(inp) for inp in df[\"B\"]]\n",
    "stat_c = [len(inp) for inp in df[\"C\"]]\n",
    "stat_label = [len(inp) for inp in df[\"label\"]]\n",
    "print(\"A stat\")\n",
    "s = pd.Series(stat_a)\n",
    "print(s.describe())\n",
    "print(\"B stat\")\n",
    "s = pd.Series(stat_b)\n",
    "print(s.describe())\n",
    "print(\"C stat\")\n",
    "s = pd.Series(stat_c)\n",
    "print(s.describe())\n",
    "print(\"label stat\")\n",
    "s = pd.Series(stat_label)\n",
    "print(s.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(dataset):\n",
    "    if len(x[\"label\"]) > 1:\n",
    "        # min = None\n",
    "        # min_key = None \n",
    "        # switch_key1 = None \n",
    "        # for key,item in dataset[i].items():\n",
    "        #     print(\"key:{} len: {}\".format(key, len(item)) )\n",
    "        #     min = len(item)\n",
    "        # if min ==1:\n",
    "        #     dataset[i][]\n",
    "        # else:\n",
    "        #     print(\"!!!!!!\")\n",
    "        #     print(dataset[i])\n",
    "        text = dataset[i][\"label\"]\n",
    "        label = None\n",
    "        for _key,item in dataset[i].items():\n",
    "            if len(item) ==1:\n",
    "                label = item\n",
    "        x[label], x[\"label\"]= text,label\n",
    "        # for key,item in x.items():\n",
    "        #     print(\"key:{} len: {}\".format(key, len(item)), end=\"\" )\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-511fb7c719a2c1cb\n",
      "Reusing dataset json (/home/huijie/.cache/huggingface/datasets/json/default-511fb7c719a2c1cb/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a781237d5b964f91a9f8ff86e70a9097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=29, names=['盜竊罪', '爆竊罪', '猥褻侵犯罪', '侵害人身罪', '不小心駕駛罪', '販運危險藥物罪', '入屋犯法罪', '搶劫罪', '以欺騙手段取得財產罪', '販毒罪', '販運毒品罪', '普通襲擊罪', '洗黑錢罪', '串謀詐騙罪', '處理贓物罪', '刑事恐嚇罪', '串謀勒索罪', '非法入境罪', '強姦罪', '非禮罪', '縱火罪', '扒竊罪', '管有危險藥物罪', '危險駕駛引致他人死亡罪', '襲擊致造成身體傷害罪', '管有虛假文書罪', '使用虛假文書罪', '危險駕駛引致他人身體受嚴重傷害罪', '危險駕駛罪'], id=None),\n",
       " 'begin': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "# print(dataset[0])\n",
    "\n",
    "# stat_a = [len(inp) for inp in dataset[\"A\"]]\n",
    "# stat_b = [len(inp) for inp in dataset[\"B\"]]\n",
    "# stat_c = [len(inp) for inp in dataset[\"C\"]]\n",
    "# stat_label = [len(inp) for inp in dataset[\"label\"]]\n",
    "# import pandas as pd\n",
    "# s = pd.Series(stat_a)\n",
    "# print(s.describe())\n",
    "# s = pd.Series(stat_b)\n",
    "# print(s.describe())\n",
    "# s = pd.Series(stat_c)\n",
    "# print(s.describe())\n",
    "# s = pd.Series(stat_label)\n",
    "# print(s.describe())\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "features = Features({\"text\": Value(\"string\"),\"label\":ClassLabel(num_classes = 29,names=['盜竊罪', '爆竊罪', '猥褻侵犯罪', '侵害人身罪', '不小心駕駛罪', '販運危險藥物罪', '入屋犯法罪', \n",
    "            '搶劫罪', '以欺騙手段取得財產罪', '販毒罪', '販運毒品罪', '普通襲擊罪', '洗黑錢罪', '串謀詐騙罪', \n",
    "            '處理贓物罪', '刑事恐嚇罪', '串謀勒索罪', '非法入境罪', '強姦罪', '非禮罪', '縱火罪', '扒竊罪', \n",
    "            '管有危險藥物罪', '危險駕駛引致他人死亡罪', '襲擊致造成身體傷害罪', '管有虛假文書罪', '使用虛假文書罪',\n",
    "             '危險駕駛引致他人身體受嚴重傷害罪', '危險駕駛罪']) ,\"begin\": Value(\"string\")})\n",
    "dataset = load_dataset(\"json\", data_files=\"/home/huijie/legal/crime_prediction/data_prepare/crime_prediction.json\",features=features)\n",
    "dataset = dataset[\"train\"]\n",
    "dataset.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/huijie/.cache/huggingface/datasets/json/default-511fb7c719a2c1cb/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-6849bb085e66de49.arrow\n"
     ]
    }
   ],
   "source": [
    "labels = ['盜竊罪', '爆竊罪', '猥褻侵犯罪', '侵害人身罪', '不小心駕駛罪', '販運危險藥物罪', '入屋犯法罪', \n",
    "            '搶劫罪', '以欺騙手段取得財產罪', '販毒罪', '販運毒品罪', '普通襲擊罪', '洗黑錢罪', '串謀詐騙罪', \n",
    "            '處理贓物罪', '刑事恐嚇罪', '串謀勒索罪', '非法入境罪', '強姦罪', '非禮罪', '縱火罪', '扒竊罪', \n",
    "            '管有危險藥物罪', '危險駕駛引致他人死亡罪', '襲擊致造成身體傷害罪', '管有虛假文書罪', '使用虛假文書罪',\n",
    "             '危險駕駛引致他人身體受嚴重傷害罪', '危險駕駛罪']\n",
    "label2id =  {k:v for v,k in enumerate(labels)}\n",
    "dataset = dataset.align_labels_with_mapping(label2id, \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['方第一證人需要透過手機作出紀錄。本席裁定控方第一證人當時正在依法執行公務。  陳大律師陳述，控方未能在毫無合理疑點下，證明被告的行為構成阻礙。  高等法院原訟法庭暫委法官黃崇厚（當時官階），在香港特別行政區訴尹明義 案指出，《簡易程序治罪條例》第23條和《侵害人身罪條例》第36（b）條的罪行不同，因為《簡易程序治罪條例》的條文中，沒有故意（wilful）這字眼，所以控方毋須證明被告人故意阻礙執行公務，意即毋須證明阻礙執行公務是被告人進行某行為的意圖（intention）。以《簡易程序治罪條例》第23條這罪行來說，控方',\n",
       "  ' 沒有任何法例賦予被告權力，容許他當時自行蒐證或執法，因此，縱使他真誠相信他人違反私穩法例，亦不可以强搶他人物品。立法會議員並沒此方面的權力。本席找不到任何法理支持被告搶手機的行為。被告的行為肯定是非法的武力。  基於前述，控方已在毫無合理疑點下，證明所有普通襲擊罪的控罪元素。本席裁定此項控罪罪名成立。 阻礙公職人員執行公務  根據《釋義及通則條例》第3條，公職人員（public officer）指任何在特區政府擔任受薪職位的人。控方第一證人是保安局高級行政主任，必然是公職人員。本席接納案發當日該小組負責在立法會大樓'],\n",
       " 'label': [3, 11],\n",
       " 'begin': ['許智峯是立法會議員，可以進入位於中環立法會道1號的立法會綜合大樓，履行公務。 2018年4月24日，立法會大樓會議室1內正舉行《廣深港高鐵條例草案》委員會會議。 當日，政府人員組成一個小組，成員包括保安局高級行政主任梁諾施，及六名運輸及房屋局的人員。他們在立法會大樓不同位置候命，並記錄立法會議員在草案委員會會議舉行時的行蹤。運輸及房屋局助理秘書長運輸3B黎惠珊，是該小組的組長，負責監察及統籌該小組組員；運輸及房屋局助理秘書長運輸3C鄭朗峰，是該小組統籌員；運輸及房屋局二級系統分析／程序編製主任運輸1梁榮燊，',\n",
       "  '許智峯是立法會議員，可以進入位於中環立法會道1號的立法會綜合大樓，履行公務。 2018年4月24日，立法會大樓會議室1內正舉行《廣深港高鐵條例草案》委員會會議。 當日，政府人員組成一個小組，成員包括保安局高級行政主任梁諾施，及六名運輸及房屋局的人員。他們在立法會大樓不同位置候命，並記錄立法會議員在草案委員會會議舉行時的行蹤。運輸及房屋局助理秘書長運輸3B黎惠珊，是該小組的組長，負責監察及統籌該小組組員；運輸及房屋局助理秘書長運輸3C鄭朗峰，是該小組統籌員；運輸及房屋局二級系統分析／程序編製主任運輸1梁榮燊，']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_function(examples):\n",
    "    result = tokenizer([examples[\"begin\"],examples[\"text\"]],truncation = True,max_length = 512)\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "        tokenize_function, batched=False, remove_columns=[\"begin\",\"text\"],num_proc =16\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 沒有任何法例賦予被告權力,容許他當時自行蒐證或執法,因此,縱使他真誠相信他人違反私穩法例,亦不可以强搶他人物品。立法會議員並沒此方面的權力。本席找不到任何法理支持被告搶手機的行為。被告的行為肯定是非法的武力。 基於前述,控方已在毫無合理疑點下,證明所有普通襲擊罪的控罪元素。本席裁定此項控罪罪名成立。 阻礙公職人員執行公務 根據《釋義及通則條例》第3條,公職人員(public officer)指任何在特區政府擔任受薪職位的人。控方第一證人是保安局高級行政主任,必然是公職人員。本席接納案發當日該小組負責在立法會大樓</s>\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets[0]['input_ids'][1]\n",
    "print(tokenizer.decode(tokenized_datasets[1][\"input_ids\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2id = {'B': 0, 'C': 1}\n",
    "# tokenized_datasets.align_labels_with_mapping(label2id, \"a_similar_to\")\n",
    "# tokenized_datasets = tokenized_datasets.rename_column(\"label\",\"classification\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer,padding= \"max_length\",max_length = 512,pad_to_multiple_of= 8)\n",
    "# train_dataloader = DataLoader(tokenized_datasets,8,collate_fn=data_collator)\n",
    "train_dataloader = DataLoader(tokenized_datasets,8,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"a_similar_to\"][:3]\n",
    "\n",
    "### define myself con_fucntion \n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:705\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=703'>704</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=704'>705</a>\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=706'>707</a>\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=707'>708</a>\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=708'>709</a>\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=709'>710</a>\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=710'>711</a>\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=711'>712</a>\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 186 at dim 2 (got 191)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/huijie/legal/crime_prediction/test.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/crime_prediction/test.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/crime_prediction/test.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m     label \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/crime_prediction/test.ipynb#ch0000012vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key,item \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py:221\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=219'>220</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=220'>221</a>\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=221'>222</a>\u001b[0m         features,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=222'>223</a>\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=223'>224</a>\u001b[0m         max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=224'>225</a>\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=225'>226</a>\u001b[0m         return_tensors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_tensors,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=226'>227</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=227'>228</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=228'>229</a>\u001b[0m         batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2795\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2791'>2792</a>\u001b[0m             batch_outputs[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m   <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2792'>2793</a>\u001b[0m         batch_outputs[key]\u001b[39m.\u001b[39mappend(value)\n\u001b[0;32m-> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2794'>2795</a>\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(batch_outputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=205'>206</a>\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=207'>208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=209'>210</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:721\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=715'>716</a>\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=716'>717</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=717'>718</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=718'>719</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=719'>720</a>\u001b[0m             )\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=720'>721</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=721'>722</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=722'>723</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=723'>724</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=725'>726</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    label = batch.pop(\"label\")\n",
    "    for key,item in batch.items():\n",
    "        print(key+\": \" ,item.shape)\n",
    "    out = model(**batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f43e34e48e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataloader = DataLoader(vaild,batch_size=4,collate_fn=con_fun) \n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:705\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=703'>704</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=704'>705</a>\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=706'>707</a>\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=707'>708</a>\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=708'>709</a>\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=709'>710</a>\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=710'>711</a>\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=711'>712</a>\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/huijie/legal/mymodel/test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/mymodel/test.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/mymodel/test.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m eval_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/mymodel/test.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m     a \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blpk-gpu1.cs.hku.hk/home/huijie/legal/mymodel/test.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(a)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py:221\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=219'>220</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=220'>221</a>\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=221'>222</a>\u001b[0m         features,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=222'>223</a>\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=223'>224</a>\u001b[0m         max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=224'>225</a>\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=225'>226</a>\u001b[0m         return_tensors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_tensors,\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=226'>227</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=227'>228</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/data/data_collator.py?line=228'>229</a>\u001b[0m         batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2795\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2791'>2792</a>\u001b[0m             batch_outputs[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m   <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2792'>2793</a>\u001b[0m         batch_outputs[key]\u001b[39m.\u001b[39mappend(value)\n\u001b[0;32m-> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2794'>2795</a>\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(batch_outputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=205'>206</a>\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=207'>208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=209'>210</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:721\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=715'>716</a>\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=716'>717</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=717'>718</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=718'>719</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=719'>720</a>\u001b[0m             )\n\u001b[0;32m--> <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=720'>721</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=721'>722</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=722'>723</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=723'>724</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/huijie/miniconda3/envs/hugface/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=725'>726</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    a = batch.pop(\"classification\")\n",
    "    print(a)\n",
    "    print(batch)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "344c146f3d74f7efd360abb5a7510a11c28372d218d34b58ffcf5f0c0e1377b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('hugface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
